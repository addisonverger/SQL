--Challenges provided by DataLemur: https://datalemur.com/
--All answers written in PostgreSQL

--Page With No Likes

SELECT page_id
FROM pages
WHERE page_id NOT IN (SELECT page_id FROM page_likes);

--Unfinished Parts

SELECT part, assembly_step
FROM parts_assembly
WHERE finish_date IS NULL;

--Histogram of Tweets

SELECT tweet_bucket, COUNT(*) AS users_num
FROM (
  SELECT COUNT(tweet_id) AS tweet_bucket
  FROM tweets
  WHERE EXTRACT('Year' FROM tweet_date) = 2022
  GROUP BY user_id
) tweet_bucket_counts
GROUP BY 1;

--Laptop vs. Mobile Viewership

SELECT 
  SUM(CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END) AS laptop_views,
  SUM(CASE WHEN device_type = 'tablet' OR device_type = 'phone' THEN 1 ELSE 0 END) AS laptop_views
FROM viewership;

--Data Science Skills

SELECT candidate_id
FROM candidates
WHERE skill IN ('Python', 'Tableau', 'PostgreSQL')
GROUP BY 1
HAVING COUNT(skill) = 3
ORDER BY 1 ASC;

--Average Post Hiatus (Part 1)

SELECT 
  user_id, 
  DATE_PART('day', MAX(post_date)::timestamp - MIN(post_date)::timestamp) AS days_between
FROM posts
WHERE user_id IN (
  SELECT user_id
  FROM posts
  WHERE EXTRACT('Year' FROM post_date) = 2021
  GROUP BY 1
  HAVING COUNT(post_id) >= 2
) 
GROUP BY 1;

--Teams Power Users

SELECT sender_id, COUNT(message_id) AS message_count
FROM messages
WHERE EXTRACT('Year' FROM sent_date) = 2022
AND EXTRACT('Month' FROM sent_date) = 8
GROUP BY 1
ORDER BY 2 DESC
LIMIT 2;

--Duplicate Job Listings

SELECT COUNT(DISTINCT jl1.company_id) AS duplicate_companies
FROM job_listings jl1
JOIN job_listings jl2
ON jl1.company_id = jl2.company_id
AND jl1.title = jl2.title
AND jl1.description = jl2.description
AND jl1.job_id != jl2.job_id;

--Cities With Completed Trades

SELECT u.city, COUNT(t.order_id) AS total_orders
FROM users u
JOIN trades t
ON u.user_id = t.user_id
AND t.status = 'Completed'
GROUP BY 1
ORDER BY 2 DESC
LIMIT 3;

--Average Review Ratings

SELECT 
  EXTRACT('MONTH' FROM submit_date) AS mth,
  product_id AS product,
  ROUND(AVG(stars), 2) AS avg_stars
FROM reviews
GROUP BY 1, 2
ORDER BY 1, 2;

--App Click-through Rate (CTR)

SELECT 
  app_id,
  ROUND(100.0 * COUNT(CASE WHEN event_type = 'click' THEN event_type ELSE NULL END) / COUNT(CASE WHEN event_type = 'impression' THEN event_type ELSE NULL END), 2) AS ctr
FROM events
WHERE EXTRACT('Year' FROM timestamp) = 2022
GROUP BY 1;

--Second Day Confirmation

SELECT e.user_id
FROM emails e 
JOIN texts t
ON e.email_id = t.email_id
AND t.signup_action = 'Confirmed'
AND DATE_PART('day', t.action_date - e.signup_date) = 1;

--Cards Issued Difference

SELECT
  card_name,
  MAX(issued_amount) - MIN(issued_amount) AS difference
FROM monthly_cards_issued
GROUP BY 1
ORDER BY 2 DESC;

--Compressed Mean

SELECT ROUND(SUM(CAST(item_count AS DECIMAL) * order_occurrences) / SUM(order_occurrences), 1) AS mean
FROM items_per_order;

--Pharmacy Analytics (Part 1)

SELECT drug, total_sales - cogs AS total_profit
FROM pharmacy_sales
ORDER BY 2 DESC
LIMIT 3;

--Pharmacy Analytics (Part 2)

SELECT 
  manufacturer, 
  COUNT(drug) AS drug_count,
  SUM(ABS(total_sales - cogs)) AS total_loss
FROM pharmacy_sales
WHERE total_sales - cogs < 0
GROUP BY 1
ORDER BY 3 DESC;

--Pharmacy Analytics (Part 3)

SELECT
  manufacturer,
  CONCAT('$', (ROUND(SUM(total_sales) / 1000000)), ' million') AS sale
FROM pharmacy_sales
GROUP BY 1
ORDER BY SUM(total_sales) DESC;

--Patient Support Analysis (Part 1)

SELECT COUNT(member_calls) AS member_count
FROM (
  SELECT COUNT(case_id) AS member_calls
  FROM callers
  GROUP BY policy_holder_id
  HAVING COUNT(case_id) >= 3
) member_calls_count;

--Patient Support Analysis (Part 2)

SELECT 
  ROUND(100.0 * COUNT(case_id) FILTER (WHERE call_category = 'n/a' OR call_category IS NULL) / COUNT(case_id), 1) AS call_percentage
FROM callers;

--User's Third Transaction

SELECT user_id, spend, transaction_date
FROM (
  SELECT user_id, spend, transaction_date, RANK() OVER (PARTITION BY user_id ORDER BY transaction_date) AS rnk
  FROM transactions
) transactions_rnk
WHERE rnk = 3;

--Sending vs. Opening Snaps

SELECT 
  b.age_bucket, 
  ROUND(100.0 * SUM(a.time_spent) FILTER (WHERE a.activity_type = 'send') / SUM(a.time_spent), 2) AS send_perc,
  ROUND(100.0 * SUM(a.time_spent) FILTER (WHERE a.activity_type = 'open') / SUM(a.time_spent), 2) AS open_perc
FROM activities a
JOIN age_breakdown b
ON a.user_id = b.user_id
WHERE a.activity_type IN ('send', 'open')
GROUP BY 1;

--Tweets' Rolling Averages

SELECT 
  user_id,
  tweet_date,
  ROUND(AVG(tweet_count)
    OVER(PARTITION BY user_id ORDER BY tweet_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW), 2)
    AS rolling_avg_3d
FROM tweets;
