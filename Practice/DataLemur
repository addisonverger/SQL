--Challenges provided by DataLemur: https://datalemur.com/
--All answers written in PostgreSQL

--Page With No Likes

SELECT page_id
FROM pages
WHERE page_id NOT IN (SELECT page_id FROM page_likes);

--Unfinished Parts

SELECT part, assembly_step
FROM parts_assembly
WHERE finish_date IS NULL;

--Histogram of Tweets

SELECT tweet_bucket, COUNT(*) AS users_num
FROM (
  SELECT COUNT(tweet_id) AS tweet_bucket
  FROM tweets
  WHERE EXTRACT('Year' FROM tweet_date) = 2022
  GROUP BY user_id
) tweet_bucket_counts
GROUP BY 1;

--Laptop vs. Mobile Viewership

SELECT 
  SUM(CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END) AS laptop_views,
  SUM(CASE WHEN device_type = 'tablet' OR device_type = 'phone' THEN 1 ELSE 0 END) AS laptop_views
FROM viewership;

--Data Science Skills

SELECT candidate_id
FROM candidates
WHERE skill IN ('Python', 'Tableau', 'PostgreSQL')
GROUP BY 1
HAVING COUNT(skill) = 3
ORDER BY 1 ASC;

--Average Post Hiatus (Part 1)

SELECT 
  user_id, 
  DATE_PART('day', MAX(post_date)::timestamp - MIN(post_date)::timestamp) AS days_between
FROM posts
WHERE user_id IN (
  SELECT user_id
  FROM posts
  WHERE EXTRACT('Year' FROM post_date) = 2021
  GROUP BY 1
  HAVING COUNT(post_id) >= 2
) 
GROUP BY 1;

--Teams Power Users

SELECT sender_id, COUNT(message_id) AS message_count
FROM messages
WHERE EXTRACT('Year' FROM sent_date) = 2022
AND EXTRACT('Month' FROM sent_date) = 8
GROUP BY 1
ORDER BY 2 DESC
LIMIT 2;

--Duplicate Job Listings

SELECT COUNT(DISTINCT jl1.company_id) AS duplicate_companies
FROM job_listings jl1
JOIN job_listings jl2
ON jl1.company_id = jl2.company_id
AND jl1.title = jl2.title
AND jl1.description = jl2.description
AND jl1.job_id != jl2.job_id;

--Cities With Completed Trades

SELECT u.city, COUNT(t.order_id) AS total_orders
FROM users u
JOIN trades t
ON u.user_id = t.user_id
AND t.status = 'Completed'
GROUP BY 1
ORDER BY 2 DESC
LIMIT 3;

--Average Review Ratings

SELECT 
  EXTRACT('MONTH' FROM submit_date) AS mth,
  product_id AS product,
  ROUND(AVG(stars), 2) AS avg_stars
FROM reviews
GROUP BY 1, 2
ORDER BY 1, 2;

--App Click-through Rate (CTR)

SELECT 
  app_id,
  ROUND(100.0 * COUNT(CASE WHEN event_type = 'click' THEN event_type ELSE NULL END) / COUNT(CASE WHEN event_type = 'impression' THEN event_type ELSE NULL END), 2) AS ctr
FROM events
WHERE EXTRACT('Year' FROM timestamp) = 2022
GROUP BY 1;

--Second Day Confirmation

SELECT e.user_id
FROM emails e 
JOIN texts t
ON e.email_id = t.email_id
AND t.signup_action = 'Confirmed'
AND DATE_PART('day', t.action_date - e.signup_date) = 1;

--Cards Issued Difference

SELECT
  card_name,
  MAX(issued_amount) - MIN(issued_amount) AS difference
FROM monthly_cards_issued
GROUP BY 1
ORDER BY 2 DESC;

--Compressed Mean

SELECT ROUND(SUM(CAST(item_count AS DECIMAL) * order_occurrences) / SUM(order_occurrences), 1) AS mean
FROM items_per_order;

--Pharmacy Analytics (Part 1)

SELECT drug, total_sales - cogs AS total_profit
FROM pharmacy_sales
ORDER BY 2 DESC
LIMIT 3;

--Pharmacy Analytics (Part 2)

SELECT 
  manufacturer, 
  COUNT(drug) AS drug_count,
  SUM(ABS(total_sales - cogs)) AS total_loss
FROM pharmacy_sales
WHERE total_sales - cogs < 0
GROUP BY 1
ORDER BY 3 DESC;

--Pharmacy Analytics (Part 3)

SELECT
  manufacturer,
  CONCAT('$', (ROUND(SUM(total_sales) / 1000000)), ' million') AS sale
FROM pharmacy_sales
GROUP BY 1
ORDER BY SUM(total_sales) DESC;

--Patient Support Analysis (Part 1)

SELECT COUNT(member_calls) AS member_count
FROM (
  SELECT COUNT(case_id) AS member_calls
  FROM callers
  GROUP BY policy_holder_id
  HAVING COUNT(case_id) >= 3
) member_calls_count;

--Patient Support Analysis (Part 2)

SELECT 
  ROUND(100.0 * COUNT(case_id) FILTER (WHERE call_category = 'n/a' OR call_category IS NULL) / COUNT(case_id), 1) AS call_percentage
FROM callers;

--User's Third Transaction

SELECT user_id, spend, transaction_date
FROM (
  SELECT user_id, spend, transaction_date, RANK() OVER (PARTITION BY user_id ORDER BY transaction_date) AS rnk
  FROM transactions
) transactions_rnk
WHERE rnk = 3;

--Sending vs. Opening Snaps

SELECT 
  b.age_bucket, 
  ROUND(100.0 * SUM(a.time_spent) FILTER (WHERE a.activity_type = 'send') / SUM(a.time_spent), 2) AS send_perc,
  ROUND(100.0 * SUM(a.time_spent) FILTER (WHERE a.activity_type = 'open') / SUM(a.time_spent), 2) AS open_perc
FROM activities a
JOIN age_breakdown b
ON a.user_id = b.user_id
WHERE a.activity_type IN ('send', 'open')
GROUP BY 1;

--Tweets' Rolling Averages

SELECT 
  user_id,
  tweet_date,
  ROUND(AVG(tweet_count)
    OVER(PARTITION BY user_id ORDER BY tweet_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW), 2)
    AS rolling_avg_3d
FROM tweets;

--Highest-Grossing Items 

WITH total_spend_rnk_cte AS (
  SELECT
    category,
    product,
    SUM(spend) AS total_spend,
    RANK() OVER (PARTITION BY category ORDER BY SUM(spend) DESC) AS rnk
  FROM product_spend
  WHERE EXTRACT("Year" FROM transaction_date) = 2022
  GROUP BY 1, 2
)

SELECT category, product, total_spend
FROM total_spend_rnk_cte
WHERE rnk IN (1, 2)
ORDER BY 1, 3 DESC;

--Top 5 Artists

WITH top_10_rnk_cte AS (
  SELECT 
    a.artist_name,
    COUNT(*) AS top_10_cnt,
    DENSE_RANK() OVER (ORDER BY COUNT(*) DESC) AS artist_rank
  FROM artists a  
  JOIN songs s 
  ON a.artist_id = s.artist_id
  JOIN global_song_rank g  
  ON s.song_id = g.song_id
  WHERE g.rank <= 10
  GROUP BY 1
)

SELECT artist_name, artist_rank
FROM top_10_rnk_cte
WHERE artist_rank IN (1, 2, 3, 4, 5);

--Signup Activation Rate

SELECT 
  ROUND(CAST(COUNT(DISTINCT e.user_id) FILTER (WHERE t.signup_action = 'Confirmed') AS DECIMAL) /
  COUNT(DISTINCT e.user_id), 2) AS confirm_rate
FROM emails e  
LEFT JOIN texts t  
ON e.email_id = t.email_id;

--Supercloud Customer

SELECT c.customer_id
FROM customer_contracts c  
JOIN products p  
ON c.product_id = p.product_id
GROUP BY 1
HAVING COUNT(DISTINCT p.product_category) = (
  SELECT COUNT(DISTINCT product_category)
  FROM products
);

--Odd and Even Measurements 

WITH measurement_rnk_CTE AS (
  SELECT 
    DENSE_RANK() OVER (PARTITION BY EXTRACT('Day' FROM measurement_time) ORDER BY measurement_time) AS dns_rnk,
    measurement_value,
    DATE(measurement_time) AS measurement_day
  FROM measurements
)

SELECT 
  measurement_day, 
  SUM(measurement_value) FILTER (WHERE dns_rnk % 2 != 0) AS odd_sum,
  SUM(measurement_value) FILTER (WHERE dns_rnk % 2 = 0) AS even_sum
FROM measurement_rnk_CTE
GROUP BY 1
ORDER BY 1;

--Histogram of Users and Purchases

WITH purch_cnt_per_day_CTE AS (
  SELECT transaction_date, user_id, COUNT(product_id) AS purchase_count
  FROM user_transactions
  GROUP BY 1, 2
), max_trans_date_per_user_CTE AS (
  SELECT MAX(transaction_date) AS transaction_date, user_id
  FROM user_transactions
  GROUP BY 2
)

SELECT m.transaction_date, m.user_id, p.purchase_count
FROM max_trans_date_per_user_CTE m  
JOIN purch_cnt_per_day_CTE p  
ON m.transaction_date = p.transaction_date
AND m.user_id = p.user_id
ORDER BY 1, 2;

--Compressed Mode

SELECT item_count
FROM items_per_order
WHERE order_occurrences = (
  SELECT MAX(order_occurrences)
  FROM items_per_order
)
ORDER BY 1 ASC;
