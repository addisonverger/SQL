--Challenges provided by DataLemur: https://datalemur.com/
--All answers written in PostgreSQL

--Page With No Likes

SELECT page_id
FROM pages
WHERE page_id NOT IN (SELECT page_id FROM page_likes);

--Unfinished Parts

SELECT part, assembly_step
FROM parts_assembly
WHERE finish_date IS NULL;

--Histogram of Tweets

SELECT tweet_bucket, COUNT(*) AS users_num
FROM (
  SELECT COUNT(tweet_id) AS tweet_bucket
  FROM tweets
  WHERE EXTRACT('Year' FROM tweet_date) = 2022
  GROUP BY user_id
) tweet_bucket_counts
GROUP BY 1;

--Laptop vs. Mobile Viewership

SELECT 
  SUM(CASE WHEN device_type = 'laptop' THEN 1 ELSE 0 END) AS laptop_views,
  SUM(CASE WHEN device_type = 'tablet' OR device_type = 'phone' THEN 1 ELSE 0 END) AS laptop_views
FROM viewership;

--Data Science Skills

SELECT candidate_id
FROM candidates
WHERE skill IN ('Python', 'Tableau', 'PostgreSQL')
GROUP BY 1
HAVING COUNT(skill) = 3
ORDER BY 1 ASC;

--Average Post Hiatus (Part 1)

SELECT 
  user_id, 
  DATE_PART('day', MAX(post_date)::timestamp - MIN(post_date)::timestamp) AS days_between
FROM posts
WHERE user_id IN (
  SELECT user_id
  FROM posts
  WHERE EXTRACT('Year' FROM post_date) = 2021
  GROUP BY 1
  HAVING COUNT(post_id) >= 2
) 
GROUP BY 1;

--Teams Power Users

SELECT sender_id, COUNT(message_id) AS message_count
FROM messages
WHERE EXTRACT('Year' FROM sent_date) = 2022
AND EXTRACT('Month' FROM sent_date) = 8
GROUP BY 1
ORDER BY 2 DESC
LIMIT 2;

--Duplicate Job Listings

SELECT COUNT(DISTINCT jl1.company_id) AS duplicate_companies
FROM job_listings jl1
JOIN job_listings jl2
ON jl1.company_id = jl2.company_id
AND jl1.title = jl2.title
AND jl1.description = jl2.description
AND jl1.job_id != jl2.job_id;

--Cities With Completed Trades

SELECT u.city, COUNT(t.order_id) AS total_orders
FROM users u
JOIN trades t
ON u.user_id = t.user_id
AND t.status = 'Completed'
GROUP BY 1
ORDER BY 2 DESC
LIMIT 3;

--Average Review Ratings

SELECT 
  EXTRACT('MONTH' FROM submit_date) AS mth,
  product_id AS product,
  ROUND(AVG(stars), 2) AS avg_stars
FROM reviews
GROUP BY 1, 2
ORDER BY 1, 2;

--App Click-through Rate (CTR)

SELECT 
  app_id,
  ROUND(100.0 * COUNT(CASE WHEN event_type = 'click' THEN event_type ELSE NULL END) / COUNT(CASE WHEN event_type = 'impression' THEN event_type ELSE NULL END), 2) AS ctr
FROM events
WHERE EXTRACT('Year' FROM timestamp) = 2022
GROUP BY 1;

--Second Day Confirmation

SELECT e.user_id
FROM emails e 
JOIN texts t
ON e.email_id = t.email_id
AND t.signup_action = 'Confirmed'
AND DATE_PART('day', t.action_date - e.signup_date) = 1;

--Cards Issued Difference

SELECT
  card_name,
  MAX(issued_amount) - MIN(issued_amount) AS difference
FROM monthly_cards_issued
GROUP BY 1
ORDER BY 2 DESC;

--Compressed Mean

SELECT ROUND(SUM(CAST(item_count AS DECIMAL) * order_occurrences) / SUM(order_occurrences), 1) AS mean
FROM items_per_order;

--Pharmacy Analytics (Part 1)

SELECT drug, total_sales - cogs AS total_profit
FROM pharmacy_sales
ORDER BY 2 DESC
LIMIT 3;

--Pharmacy Analytics (Part 2)

SELECT 
  manufacturer, 
  COUNT(drug) AS drug_count,
  SUM(ABS(total_sales - cogs)) AS total_loss
FROM pharmacy_sales
WHERE total_sales - cogs < 0
GROUP BY 1
ORDER BY 3 DESC;

--Pharmacy Analytics (Part 3)

SELECT
  manufacturer,
  CONCAT('$', (ROUND(SUM(total_sales) / 1000000)), ' million') AS sale
FROM pharmacy_sales
GROUP BY 1
ORDER BY SUM(total_sales) DESC;

--Patient Support Analysis (Part 1)

SELECT COUNT(member_calls) AS member_count
FROM (
  SELECT COUNT(case_id) AS member_calls
  FROM callers
  GROUP BY policy_holder_id
  HAVING COUNT(case_id) >= 3
) member_calls_count;

--Patient Support Analysis (Part 2)

SELECT 
  ROUND(100.0 * COUNT(case_id) FILTER (WHERE call_category = 'n/a' OR call_category IS NULL) / COUNT(case_id), 1) AS call_percentage
FROM callers;

--User's Third Transaction

SELECT user_id, spend, transaction_date
FROM (
  SELECT user_id, spend, transaction_date, RANK() OVER (PARTITION BY user_id ORDER BY transaction_date) AS rnk
  FROM transactions
) transactions_rnk
WHERE rnk = 3;

--Sending vs. Opening Snaps

SELECT 
  b.age_bucket, 
  ROUND(100.0 * SUM(a.time_spent) FILTER (WHERE a.activity_type = 'send') / SUM(a.time_spent), 2) AS send_perc,
  ROUND(100.0 * SUM(a.time_spent) FILTER (WHERE a.activity_type = 'open') / SUM(a.time_spent), 2) AS open_perc
FROM activities a
JOIN age_breakdown b
ON a.user_id = b.user_id
WHERE a.activity_type IN ('send', 'open')
GROUP BY 1;

--Tweets' Rolling Averages

SELECT 
  user_id,
  tweet_date,
  ROUND(AVG(tweet_count)
    OVER(PARTITION BY user_id ORDER BY tweet_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW), 2)
    AS rolling_avg_3d
FROM tweets;

--Highest-Grossing Items 

WITH total_spend_rnk_cte AS (
  SELECT
    category,
    product,
    SUM(spend) AS total_spend,
    RANK() OVER (PARTITION BY category ORDER BY SUM(spend) DESC) AS rnk
  FROM product_spend
  WHERE EXTRACT("Year" FROM transaction_date) = 2022
  GROUP BY 1, 2
)

SELECT category, product, total_spend
FROM total_spend_rnk_cte
WHERE rnk IN (1, 2)
ORDER BY 1, 3 DESC;

--Top 5 Artists

WITH top_10_rnk_cte AS (
  SELECT 
    a.artist_name,
    COUNT(*) AS top_10_cnt,
    DENSE_RANK() OVER (ORDER BY COUNT(*) DESC) AS artist_rank
  FROM artists a  
  JOIN songs s 
  ON a.artist_id = s.artist_id
  JOIN global_song_rank g  
  ON s.song_id = g.song_id
  WHERE g.rank <= 10
  GROUP BY 1
)

SELECT artist_name, artist_rank
FROM top_10_rnk_cte
WHERE artist_rank IN (1, 2, 3, 4, 5);

--Signup Activation Rate

SELECT 
  ROUND(CAST(COUNT(DISTINCT e.user_id) FILTER (WHERE t.signup_action = 'Confirmed') AS DECIMAL) /
  COUNT(DISTINCT e.user_id), 2) AS confirm_rate
FROM emails e  
LEFT JOIN texts t  
ON e.email_id = t.email_id;

--Supercloud Customer

SELECT c.customer_id
FROM customer_contracts c  
JOIN products p  
ON c.product_id = p.product_id
GROUP BY 1
HAVING COUNT(DISTINCT p.product_category) = (
  SELECT COUNT(DISTINCT product_category)
  FROM products
);

--Odd and Even Measurements 

WITH measurement_rnk_CTE AS (
  SELECT 
    DENSE_RANK() OVER (PARTITION BY EXTRACT('Day' FROM measurement_time) ORDER BY measurement_time) AS dns_rnk,
    measurement_value,
    DATE(measurement_time) AS measurement_day
  FROM measurements
)

SELECT 
  measurement_day, 
  SUM(measurement_value) FILTER (WHERE dns_rnk % 2 != 0) AS odd_sum,
  SUM(measurement_value) FILTER (WHERE dns_rnk % 2 = 0) AS even_sum
FROM measurement_rnk_CTE
GROUP BY 1
ORDER BY 1;

--Histogram of Users and Purchases

WITH purch_cnt_per_day_CTE AS (
  SELECT transaction_date, user_id, COUNT(product_id) AS purchase_count
  FROM user_transactions
  GROUP BY 1, 2
), max_trans_date_per_user_CTE AS (
  SELECT MAX(transaction_date) AS transaction_date, user_id
  FROM user_transactions
  GROUP BY 2
)

SELECT m.transaction_date, m.user_id, p.purchase_count
FROM max_trans_date_per_user_CTE m  
JOIN purch_cnt_per_day_CTE p  
ON m.transaction_date = p.transaction_date
AND m.user_id = p.user_id
ORDER BY 1, 2;

--Compressed Mode

SELECT item_count
FROM items_per_order
WHERE order_occurrences = (
  SELECT MAX(order_occurrences)
  FROM items_per_order
)
ORDER BY 1 ASC;

--Card Launch Success

WITH launch_date_CTE AS (
  SELECT 
    card_name, 
    MAKE_DATE(issue_year, issue_month, 1) AS issue_date,
    issued_amount,
    MIN(MAKE_DATE(issue_year, issue_month, 1)) OVER (PARTITION BY card_name) AS launch_date
  FROM monthly_cards_issued
)

SELECT card_name, issued_amount
FROM launch_date_CTE
WHERE issue_date = launch_date
ORDER BY 2 DESC;

--International Call Percentage

SELECT ROUND(100.0 * COUNT(*) FILTER (WHERE ci.country_id <> ri.country_id) / COUNT(*), 1) AS international_calls_pct
FROM phone_calls c  
LEFT JOIN phone_info ci  
ON c.caller_id = ci.caller_id
LEFT JOIN phone_info ri  
ON c.receiver_id = ri.caller_id;

--Active User Retention

WITH july_users_CTE AS (
  SELECT DISTINCT user_id
  FROM user_actions
  WHERE EXTRACT('Month' FROM event_date) = 7
  AND EXTRACT('Year' FROM event_date) = 2022
), june_user_CTE AS (
  SELECT DISTINCT user_id
  FROM user_actions
  WHERE EXTRACT('Month' FROM event_date) = 6
  AND EXTRACT('Year' FROM event_date) = 2022
)

SELECT 7 AS month, COUNT(user_id) AS monthly_active_users
FROM july_users_CTE
WHERE user_id IN (SELECT user_id FROM june_user_CTE);

--Y-on-Y Growth Rate

SELECT 
  EXTRACT('Year' FROM u1.transaction_date) AS year,
  u1.product_id,
  SUM(u1.spend) AS curr_year_spend,
  SUM(u2.spend) AS prev_year_spend,
  ROUND(100.0 * (SUM(u1.spend) - SUM(u2.spend)) / SUM(u2.spend), 2) AS yoy_rate
FROM user_transactions u1
LEFT JOIN user_transactions u2
ON u1.product_id = u2.product_id
AND EXTRACT('Year' FROM u1.transaction_date) - 1 = EXTRACT('Year' FROM u2.transaction_date)
GROUP BY 1, 2
ORDER BY 2;

--Maximize Prime Item Inventory

WITH type_totals_CTE AS (
  SELECT
    item_type,
    SUM(square_footage) AS total_sqft,
    COUNT(item_id) AS item_count
  FROM inventory
  GROUP BY 1
), prime_CTE AS (
  SELECT
    item_type,
    total_sqft,
    FLOOR(500000 / total_sqft) AS max_combos,
    FLOOR(500000 / total_sqft) * item_count AS max_items
  FROM type_totals_CTE
  WHERE item_type = 'prime_eligible'
), not_prime_CTE AS (
  SELECT
    item_type,
    total_sqft,
    FLOOR((500000 - (SELECT total_sqft * max_combos FROM prime_CTE)) / total_sqft) * item_count AS item_count
  FROM type_totals_CTE
  WHERE item_type = 'not_prime'
)

SELECT item_type, max_items
FROM prime_CTE
UNION ALL
SELECT item_type, item_count
FROM not_prime_CTE;

--Median Google Search Frequency

WITH searches_expanded AS (
  SELECT searches
  FROM search_frequency
  GROUP BY searches,
    GENERATE_SERIES(1, num_users)
)

SELECT 
  PERCENTILE_CONT(0.5)
    WITHIN GROUP (
      ORDER BY searches) AS median
FROM searches_expanded;

--Advertiser Status

SELECT 
  COALESCE(a.user_id, d.user_id) AS user_id, 
  CASE
    WHEN a.status IS NULL AND d.paid IS NOT NULL
    THEN 'NEW'
    WHEN a.status IN ('NEW', 'EXISTING', 'RESURRECT') AND d.paid IS NOT NULL
    THEN 'EXISTING'
    WHEN d.paid IS NULL
    THEN 'CHURN'
    WHEN a.status = 'CHURN' AND d.paid IS NOT NULL
    THEN 'RESURRECT'
    ELSE NULL
  END AS new_status
FROM advertiser a
FULL OUTER JOIN daily_pay d
ON a.user_id = d.user_id
ORDER BY 1;

--3-Topping Pizzas

SELECT 
  CONCAT_WS(',', p1.topping_name, p2.topping_name, p3.topping_name) AS pizza,
  p1.ingredient_cost + p2.ingredient_cost + p3.ingredient_cost AS total_cost 
FROM pizza_toppings p1
CROSS JOIN pizza_toppings p2, pizza_toppings p3
WHERE p1.topping_name < p2.topping_name
AND p2.topping_name < p3.topping_name
ORDER BY 2 DESC, 1 ASC;

--Patient Support Analysis (Part 3)

WITH time_difference_CTE AS (
  SELECT
    policy_holder_id,
    call_received AS current_call,
    LAG(call_received) OVER (PARTITION BY policy_holder_id ORDER BY call_received) AS previous_call,
    EXTRACT(EPOCH FROM call_received - LAG(call_received) OVER (PARTITION BY policy_holder_id ORDER BY call_received))/(24*60*60) AS time_difference
  FROM callers
)

SELECT COUNT(DISTINCT policy_holder_id) AS patient_count
FROM time_difference_CTE
WHERE time_difference <= 7;
